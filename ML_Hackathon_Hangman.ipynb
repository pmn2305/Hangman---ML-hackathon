{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ML Hackathon Project â€” Hangman Solver using HMM + Q-Learning\n",
        "\n",
        "## Overview\n",
        "This project implements an intelligent Hangman solver using a combination of **Hidden Markov Models (HMM)** and **Reinforcement Learning (Q-Learning)**.  \n",
        "It learns the statistical structure of English words and adapts its guessing strategy over time.\n",
        "\n",
        "## Features\n",
        "- Enhanced HMM with unigram, bigram, and trigram frequency modeling.\n",
        "- Q-learning agent that optimizes letter-guessing decisions.\n",
        "- End-to-end training and testing pipeline with modular components.\n",
        "- Supports model persistence and evaluation across rounds.\n",
        "\n",
        "## Usage\n",
        "Place your `corpus.txt` and `test.txt` files in the same directory as this notebook, then run all cells in order.  \n",
        "The system will train the HMM, initialize the Q-agent, and begin solving Hangman rounds automatically.\n",
        "\n"
      ],
      "metadata": {
        "id": "dOhjX-VdECcN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tsn8xJhS7wK6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict, Counter\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import random\n",
        "\n",
        "# ============================================================================\n",
        "# HMM\n",
        "# ============================================================================\n",
        "\n",
        "class ImprovedHMM:\n",
        "    \"\"\"Enhanced HMM with better word matching and frequency analysis\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.words_by_length = defaultdict(list)\n",
        "        self.letter_freq = Counter()\n",
        "        self.position_freq = defaultdict(lambda: defaultdict(Counter))\n",
        "        self.bigram_freq = defaultdict(Counter)\n",
        "        self.trigram_freq = defaultdict(lambda: defaultdict(Counter))\n",
        "        self.first_letter_freq = Counter()\n",
        "        self.last_letter_freq = Counter()\n",
        "        self.pattern_cache = {}\n",
        "\n",
        "    def train(self, words):\n",
        "        print(\"Training Enhanced HMM...\")\n",
        "\n",
        "        for word in words:\n",
        "            word = word.lower().strip()\n",
        "            if not word or not word.isalpha():\n",
        "                continue\n",
        "\n",
        "            length = len(word)\n",
        "            self.words_by_length[length].append(word)\n",
        "\n",
        "            # Global frequency\n",
        "            self.letter_freq.update(word)\n",
        "\n",
        "            # Positional frequency\n",
        "            for i, char in enumerate(word):\n",
        "                self.position_freq[length][i][char] += 1\n",
        "\n",
        "            # Bigrams\n",
        "            for i in range(len(word) - 1):\n",
        "                self.bigram_freq[word[i]][word[i+1]] += 1\n",
        "\n",
        "            # Trigrams\n",
        "            for i in range(len(word) - 2):\n",
        "                self.trigram_freq[word[i]][word[i+1]][word[i+2]] += 1\n",
        "\n",
        "            # First and last letters\n",
        "            if len(word) > 0:\n",
        "                self.first_letter_freq[word[0]] += 1\n",
        "                self.last_letter_freq[word[-1]] += 1\n",
        "\n",
        "        # Normalize frequencies\n",
        "        total = sum(self.letter_freq.values())\n",
        "        self.letter_freq = {k: v/total for k, v in self.letter_freq.items()}\n",
        "\n",
        "        print(f\"Trained on {sum(len(v) for v in self.words_by_length.values())} words\")\n",
        "        print(f\"Top 10 letters: {sorted(self.letter_freq.items(), key=lambda x: -x[1])[:10]}\")\n",
        "\n",
        "    def get_matches(self, mask, guessed):\n",
        "        \"\"\"Find matching words with caching\"\"\"\n",
        "        cache_key = (mask, tuple(sorted(guessed)))\n",
        "        if cache_key in self.pattern_cache:\n",
        "            return self.pattern_cache[cache_key]\n",
        "\n",
        "        length = len(mask)\n",
        "        if length not in self.words_by_length:\n",
        "            return []\n",
        "\n",
        "        matches = []\n",
        "        for word in self.words_by_length[length]:\n",
        "            if self._matches(word, mask, guessed):\n",
        "                matches.append(word)\n",
        "\n",
        "        # Cache result (limit cache size)\n",
        "        if len(self.pattern_cache) < 10000:\n",
        "            self.pattern_cache[cache_key] = matches\n",
        "\n",
        "        return matches\n",
        "\n",
        "    def _matches(self, word, mask, guessed):\n",
        "        \"\"\"Check if word matches mask and constraints\"\"\"\n",
        "        for w, m in zip(word, mask):\n",
        "            if m != '_':\n",
        "                if w != m:\n",
        "                    return False\n",
        "            else:\n",
        "                if w in guessed:\n",
        "                    return False\n",
        "        return True\n",
        "\n",
        "    def get_letter_probabilities(self, mask, guessed):\n",
        "        \"\"\"Get probability distribution over letters\"\"\"\n",
        "        remaining = set('abcdefghijklmnopqrstuvwxyz') - guessed\n",
        "\n",
        "        if not remaining:\n",
        "            return {}\n",
        "\n",
        "        combined_scores = Counter()\n",
        "\n",
        "        # Strategy 1: Direct pattern matching (HIGHEST WEIGHT)\n",
        "        matches = self.get_matches(mask, guessed)\n",
        "\n",
        "        if 0 < len(matches) <= 2000:\n",
        "            for word in matches:\n",
        "                word_letters = set(word) & remaining\n",
        "                for letter in word_letters:\n",
        "                    count = word.count(letter)\n",
        "                    combined_scores[letter] += count * 1000\n",
        "\n",
        "        # Strategy 2: Positional frequency\n",
        "        length = len(mask)\n",
        "        if length in self.position_freq:\n",
        "            for i, m in enumerate(mask):\n",
        "                if m == '_' and i in self.position_freq[length]:\n",
        "                    for letter in remaining:\n",
        "                        combined_scores[letter] += self.position_freq[length][i].get(letter, 0) * 100\n",
        "\n",
        "        # Strategy 3: Trigram context\n",
        "        for i, m in enumerate(mask):\n",
        "            if m == '_':\n",
        "                # Left bigram context\n",
        "                if i >= 2 and mask[i-2] != '_' and mask[i-1] != '_':\n",
        "                    left2, left1 = mask[i-2], mask[i-1]\n",
        "                    if left2 in self.trigram_freq and left1 in self.trigram_freq[left2]:\n",
        "                        for letter in remaining:\n",
        "                            combined_scores[letter] += self.trigram_freq[left2][left1].get(letter, 0) * 200\n",
        "\n",
        "                # Right bigram context\n",
        "                if i <= len(mask) - 3 and mask[i+1] != '_' and mask[i+2] != '_':\n",
        "                    right1, right2 = mask[i+1], mask[i+2]\n",
        "                    for letter in remaining:\n",
        "                        if letter in self.trigram_freq and right1 in self.trigram_freq[letter]:\n",
        "                            combined_scores[letter] += self.trigram_freq[letter][right1].get(right2, 0) * 200\n",
        "\n",
        "        # Strategy 4: Bigram context\n",
        "        for i, m in enumerate(mask):\n",
        "            if m == '_':\n",
        "                if i > 0 and mask[i-1] != '_':\n",
        "                    left = mask[i-1]\n",
        "                    for letter in remaining:\n",
        "                        combined_scores[letter] += self.bigram_freq[left].get(letter, 0) * 150\n",
        "\n",
        "                if i < len(mask) - 1 and mask[i+1] != '_':\n",
        "                    right = mask[i+1]\n",
        "                    for letter in remaining:\n",
        "                        combined_scores[letter] += self.bigram_freq[letter].get(right, 0) * 150\n",
        "\n",
        "        # Strategy 5: First/last letter\n",
        "        blank_positions = [i for i, m in enumerate(mask) if m == '_']\n",
        "        if 0 in blank_positions:\n",
        "            for letter in remaining:\n",
        "                combined_scores[letter] += self.first_letter_freq.get(letter, 0) * 80\n",
        "\n",
        "        if len(mask) - 1 in blank_positions:\n",
        "            for letter in remaining:\n",
        "                combined_scores[letter] += self.last_letter_freq.get(letter, 0) * 80\n",
        "\n",
        "        # Strategy 6: Global frequency (base score)\n",
        "        for letter in remaining:\n",
        "            combined_scores[letter] += self.letter_freq.get(letter, 0) * 500\n",
        "\n",
        "        # Vowel boost in early game\n",
        "        revealed_count = sum(1 for c in mask if c != '_')\n",
        "        vowels = set('aeiou') & remaining\n",
        "        if revealed_count < len(mask) * 0.3 and len(guessed) < 5:\n",
        "            for v in vowels:\n",
        "                combined_scores[v] += 800\n",
        "\n",
        "        # Normalize to probabilities\n",
        "        total = sum(combined_scores.values())\n",
        "        if total > 0:\n",
        "            probabilities = {k: v/total for k, v in combined_scores.items()}\n",
        "        else:\n",
        "            # Uniform distribution fallback\n",
        "            probabilities = {k: 1.0/len(remaining) for k in remaining}\n",
        "\n",
        "        return probabilities\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# HANGMAN ENVIRONMENT\n",
        "# ============================================================================\n",
        "\n",
        "class HangmanEnv:\n",
        "    \"\"\"Hangman game environment for RL\"\"\"\n",
        "\n",
        "    def __init__(self, words, max_lives=6):\n",
        "        self.words = words\n",
        "        self.max_lives = max_lives\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self, word=None):\n",
        "        \"\"\"Reset environment with a new word\"\"\"\n",
        "        if word is None:\n",
        "            self.word = random.choice(self.words).lower().strip()\n",
        "        else:\n",
        "            self.word = word.lower().strip()\n",
        "\n",
        "        self.mask = ['_'] * len(self.word)\n",
        "        self.guessed = set()\n",
        "        self.lives = self.max_lives\n",
        "        self.done = False\n",
        "        self.won = False\n",
        "\n",
        "        return self._get_state()\n",
        "\n",
        "    def step(self, letter):\n",
        "        \"\"\"Take action (guess letter) and return (state, reward, done)\"\"\"\n",
        "        if self.done:\n",
        "            return self._get_state(), 0, True, {}\n",
        "\n",
        "        letter = letter.lower()\n",
        "\n",
        "        # Penalize repeated guesses\n",
        "        if letter in self.guessed:\n",
        "            reward = -5\n",
        "            return self._get_state(), reward, self.done, {'repeated': True}\n",
        "\n",
        "        self.guessed.add(letter)\n",
        "\n",
        "        # Check if letter in word\n",
        "        if letter in self.word:\n",
        "            # Correct guess\n",
        "            num_occurrences = 0\n",
        "            for i, c in enumerate(self.word):\n",
        "                if c == letter:\n",
        "                    self.mask[i] = c\n",
        "                    num_occurrences += 1\n",
        "\n",
        "            # Reward based on number of letters revealed\n",
        "            reward = 5 * num_occurrences\n",
        "\n",
        "            # Check if won\n",
        "            if '_' not in self.mask:\n",
        "                self.done = True\n",
        "                self.won = True\n",
        "                reward += 50  # Big bonus for winning\n",
        "        else:\n",
        "            # Wrong guess\n",
        "            self.lives -= 1\n",
        "            reward = -10\n",
        "\n",
        "            # Check if lost\n",
        "            if self.lives <= 0:\n",
        "                self.done = True\n",
        "                self.won = False\n",
        "                reward = -50  # Big penalty for losing\n",
        "\n",
        "        return self._get_state(), reward, self.done, {}\n",
        "\n",
        "    def _get_state(self):\n",
        "        \"\"\"Get current state representation\"\"\"\n",
        "        return {\n",
        "            'mask': ''.join(self.mask),\n",
        "            'guessed': set(self.guessed),\n",
        "            'lives': self.lives,\n",
        "            'revealed_count': sum(1 for c in self.mask if c != '_'),\n",
        "            'length': len(self.word)\n",
        "        }\n",
        "\n"
      ],
      "metadata": {
        "id": "AnqUDZxa8Zyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# Q-LEARNING RL AGENT\n",
        "# ============================================================================\n",
        "\n",
        "class QLearningAgent:\n",
        "    \"\"\"Q-Learning agent that uses HMM probabilities\"\"\"\n",
        "\n",
        "    def __init__(self, hmm, alpha=0.1, gamma=0.95, epsilon=0.3):\n",
        "        self.hmm = hmm\n",
        "        self.Q = defaultdict(lambda: defaultdict(float))\n",
        "        self.alpha = alpha  # Learning rate\n",
        "        self.gamma = gamma  # Discount factor\n",
        "        self.epsilon = epsilon  # Exploration rate\n",
        "        self.epsilon_decay = 0.995\n",
        "        self.epsilon_min = 0.05\n",
        "\n",
        "    def get_state_key(self, state):\n",
        "        \"\"\"Convert state to hashable key\"\"\"\n",
        "        mask = state['mask']\n",
        "        guessed_str = ''.join(sorted(state['guessed']))\n",
        "        lives = state['lives']\n",
        "        return f\"{mask}|{guessed_str}|{lives}\"\n",
        "\n",
        "    def choose_action(self, state, training=True):\n",
        "        \"\"\"Choose action using epsilon-greedy with HMM guidance\"\"\"\n",
        "        remaining = set('abcdefghijklmnopqrstuvwxyz') - state['guessed']\n",
        "\n",
        "        if not remaining:\n",
        "            return None\n",
        "\n",
        "        # Exploration\n",
        "        if training and random.random() < self.epsilon:\n",
        "            # Explore with HMM guidance (weighted random)\n",
        "            hmm_probs = self.hmm.get_letter_probabilities(state['mask'], state['guessed'])\n",
        "            if hmm_probs:\n",
        "                letters = list(hmm_probs.keys())\n",
        "                probs = np.array([hmm_probs[l] for l in letters])\n",
        "                probs = probs / probs.sum()\n",
        "                return np.random.choice(letters, p=probs)\n",
        "            else:\n",
        "                return random.choice(list(remaining))\n",
        "\n",
        "        # Exploitation: choose best action based on Q-values + HMM\n",
        "        state_key = self.get_state_key(state)\n",
        "        hmm_probs = self.hmm.get_letter_probabilities(state['mask'], state['guessed'])\n",
        "\n",
        "        best_score = float('-inf')\n",
        "        best_action = None\n",
        "\n",
        "        for letter in remaining:\n",
        "            # Combine Q-value with HMM probability\n",
        "            q_value = self.Q[state_key][letter]\n",
        "            hmm_prob = hmm_probs.get(letter, 0)\n",
        "\n",
        "            # Weighted combination (Q-learning gets more weight as training progresses)\n",
        "            combined_score = 0.6 * q_value + 0.4 * hmm_prob * 100\n",
        "\n",
        "            if combined_score > best_score:\n",
        "                best_score = combined_score\n",
        "                best_action = letter\n",
        "\n",
        "        return best_action if best_action else random.choice(list(remaining))\n",
        "\n",
        "    def update(self, state, action, reward, next_state, done):\n",
        "        \"\"\"Update Q-value\"\"\"\n",
        "        state_key = self.get_state_key(state)\n",
        "        next_state_key = self.get_state_key(next_state)\n",
        "\n",
        "        # Current Q-value\n",
        "        current_q = self.Q[state_key][action]\n",
        "\n",
        "        # Best next Q-value\n",
        "        if done:\n",
        "            max_next_q = 0\n",
        "        else:\n",
        "            remaining_next = set('abcdefghijklmnopqrstuvwxyz') - next_state['guessed']\n",
        "            if remaining_next:\n",
        "                max_next_q = max([self.Q[next_state_key][a] for a in remaining_next])\n",
        "            else:\n",
        "                max_next_q = 0\n",
        "\n",
        "        # Q-learning update\n",
        "        new_q = current_q + self.alpha * (reward + self.gamma * max_next_q - current_q)\n",
        "        self.Q[state_key][action] = new_q\n",
        "\n",
        "    def decay_epsilon(self):\n",
        "        \"\"\"Decay exploration rate\"\"\"\n",
        "        self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)\n"
      ],
      "metadata": {
        "id": "d6PNMcF18NFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# TRAINING\n",
        "# ============================================================================\n",
        "\n",
        "def train_rl_agent(hmm, train_words, num_episodes=10000, max_lives=6):\n",
        "    \"\"\"Train RL agent\"\"\"\n",
        "    print(f\"\\nTraining RL Agent for {num_episodes} episodes...\")\n",
        "\n",
        "    env = HangmanEnv(train_words, max_lives)\n",
        "    agent = QLearningAgent(hmm)\n",
        "\n",
        "    rewards_history = []\n",
        "    success_history = []\n",
        "\n",
        "    for episode in tqdm(range(num_episodes)):\n",
        "        state = env.reset()\n",
        "        episode_reward = 0\n",
        "\n",
        "        while not env.done:\n",
        "            action = agent.choose_action(state, training=True)\n",
        "\n",
        "            if action is None:\n",
        "                break\n",
        "\n",
        "            next_state, reward, done, info = env.step(action)\n",
        "\n",
        "            agent.update(state, action, reward, next_state, done)\n",
        "\n",
        "            episode_reward += reward\n",
        "            state = next_state\n",
        "\n",
        "        rewards_history.append(episode_reward)\n",
        "        success_history.append(1 if env.won else 0)\n",
        "\n",
        "        # Decay exploration\n",
        "        if episode % 100 == 0:\n",
        "            agent.decay_epsilon()\n",
        "\n",
        "        # Progress report\n",
        "        if (episode + 1) % 500 == 0:\n",
        "            recent_success = np.mean(success_history[-500:])\n",
        "            recent_reward = np.mean(rewards_history[-500:])\n",
        "            print(f\"Episode {episode+1}: Success Rate: {recent_success:.2%}, Avg Reward: {recent_reward:.1f}, Epsilon: {agent.epsilon:.3f}\")\n",
        "\n",
        "    return agent, rewards_history, success_history\n"
      ],
      "metadata": {
        "id": "EwU1B2Mf8GQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# EVALUATION\n",
        "# ============================================================================\n",
        "\n",
        "def evaluate_agent(agent, test_words, max_lives=6, verbose=True):\n",
        "    \"\"\"Evaluate trained agent on test set\"\"\"\n",
        "    if verbose:\n",
        "        print(f\"\\nEvaluating on {len(test_words)} words...\")\n",
        "\n",
        "    env = HangmanEnv(test_words, max_lives)\n",
        "\n",
        "    successes = 0\n",
        "    total_wrong = 0\n",
        "    total_repeated = 0\n",
        "\n",
        "    iterator = tqdm(test_words) if verbose else test_words\n",
        "\n",
        "    for word in iterator:\n",
        "        state = env.reset(word)\n",
        "\n",
        "        while not env.done:\n",
        "            action = agent.choose_action(state, training=False)\n",
        "\n",
        "            if action is None:\n",
        "                break\n",
        "\n",
        "            next_state, reward, done, info = env.step(action)\n",
        "\n",
        "            if 'repeated' in info:\n",
        "                total_repeated += 1\n",
        "            elif reward < 0:  # Wrong guess (not repeated)\n",
        "                total_wrong += 1\n",
        "\n",
        "            state = next_state\n",
        "\n",
        "        if env.won:\n",
        "            successes += 1\n",
        "\n",
        "    # Calculate metrics\n",
        "    n = len(test_words)\n",
        "    success_rate = successes / n\n",
        "    final_score = (success_rate * n) - (total_wrong * 5) - (total_repeated * 2)\n",
        "\n",
        "    if verbose:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"EVALUATION RESULTS\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"Total Games: {n}\")\n",
        "        print(f\"Wins: {successes}\")\n",
        "        print(f\"Success Rate: {success_rate:.4f} ({success_rate*100:.2f}%)\")\n",
        "        print(f\"Total Wrong Guesses: {total_wrong}\")\n",
        "        print(f\"Average Wrong per Game: {total_wrong/n:.2f}\")\n",
        "        print(f\"Total Repeated Guesses: {total_repeated}\")\n",
        "        print(f\"Average Repeated per Game: {total_repeated/n:.4f}\")\n",
        "        print(\"-\"*60)\n",
        "        print(f\"FINAL SCORE = ({success_rate:.4f} * {n}) - ({total_wrong} * 5) - ({total_repeated} * 2)\")\n",
        "        print(f\"FINAL SCORE = {success_rate * n:.2f} - {total_wrong * 5:.2f} - {total_repeated * 2:.2f}\")\n",
        "        print(f\"FINAL SCORE = {final_score:.2f}\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "    return success_rate, total_wrong, total_repeated, final_score\n"
      ],
      "metadata": {
        "id": "JlOJExUa8Cce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Load data\n",
        "    print(\"Loading corpus...\")\n",
        "    with open(\"corpus.txt\") as f:\n",
        "        corpus = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "    print(\"Loading test set...\")\n",
        "    with open(\"test.txt\") as f:\n",
        "        test_words = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "    # Train HMM\n",
        "    hmm = ImprovedHMM()\n",
        "    hmm.train(corpus)\n",
        "\n",
        "    # --------------------------------------------------------------------------\n",
        "    # QUICK EVALUATION OF HMM-ONLY ACCURACY (WITHOUT RL)\n",
        "    # --------------------------------------------------------------------------\n",
        "    print(\"\\nEvaluating pure HMM accuracy (no RL)...\")\n",
        "    correct = 0\n",
        "    total = 500  # limit to 500 random test words for quick evaluation\n",
        "\n",
        "    for word in random.sample(test_words, min(total, len(test_words))):\n",
        "        mask = \"_\" * len(word)\n",
        "        guessed = set()\n",
        "        lives = 6\n",
        "\n",
        "        while \"_\" in mask and lives > 0:\n",
        "            probs = hmm.get_letter_probabilities(mask, guessed)\n",
        "            if not probs:\n",
        "                break\n",
        "            guess = max(probs, key=probs.get)\n",
        "            guessed.add(guess)\n",
        "            if guess in word:\n",
        "                mask = \"\".join([c if c == guess or mask[i] != \"_\" else \"_\" for i, c in enumerate(word)])\n",
        "            else:\n",
        "                lives -= 1\n",
        "\n",
        "        if \"_\" not in mask:\n",
        "            correct += 1\n",
        "\n",
        "    print(f\"HMM-only Success Rate: {correct}/{total} = {correct/total:.2%}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEKbXS-8700i",
        "outputId": "b335e21b-2d9d-41b8-be97-ba4031a3a02a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading corpus...\n",
            "Loading test set...\n",
            "Training Enhanced HMM...\n",
            "Trained on 49979 words\n",
            "Top 10 letters: [('e', 0.10365422049194833), ('a', 0.08866740821262145), ('i', 0.08857892829756217), ('o', 0.07543544758197032), ('r', 0.07073547876060705), ('n', 0.0701814259591644), ('t', 0.06781564156365076), ('s', 0.06118596792813746), ('l', 0.05773525124082548), ('c', 0.04575254274422563)]\n",
            "\n",
            "Evaluating pure HMM accuracy (no RL)...\n",
            "HMM-only Success Rate: 161/500 = 32.20%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    # Train RL Agent\n",
        "    # Use subset of corpus for faster training\n",
        "    train_subset = corpus[:10000] if len(corpus) > 10000 else corpus\n",
        "    agent, rewards, successes = train_rl_agent(hmm, train_subset, num_episodes=10000)\n",
        "\n",
        "    # Evaluate on test set\n",
        "    success_rate, total_wrong, total_repeated, final_score = evaluate_agent(agent, test_words)\n",
        "\n",
        "\n",
        "    # Plot learning curves\n",
        "    print(\"\\nTraining complete!\")\n",
        "    print(f\"Final Success Rate: {success_rate:.2%}\")\n",
        "    print(f\"Final Score: {final_score:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2mYp_v9-byy",
        "outputId": "67d92d9c-f9ab-4026-c610-4e6f3ea7164f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training RL Agent for 10000 episodes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|â–Œ         | 505/10000 [00:17<06:52, 23.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 500: Success Rate: 22.60%, Avg Reward: -38.3, Epsilon: 0.293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|â–ˆ         | 1003/10000 [00:33<04:14, 35.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1000: Success Rate: 26.60%, Avg Reward: -32.0, Epsilon: 0.285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|â–ˆâ–Œ        | 1507/10000 [00:49<03:55, 36.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1500: Success Rate: 26.80%, Avg Reward: -32.2, Epsilon: 0.278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|â–ˆâ–ˆ        | 2007/10000 [01:05<03:52, 34.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 2000: Success Rate: 24.00%, Avg Reward: -34.9, Epsilon: 0.271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|â–ˆâ–ˆâ–Œ       | 2507/10000 [01:20<03:30, 35.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 2500: Success Rate: 22.20%, Avg Reward: -38.4, Epsilon: 0.265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|â–ˆâ–ˆâ–ˆ       | 3006/10000 [01:38<04:10, 27.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 3000: Success Rate: 24.20%, Avg Reward: -36.5, Epsilon: 0.258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 3506/10000 [01:53<02:59, 36.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 3500: Success Rate: 21.80%, Avg Reward: -38.4, Epsilon: 0.252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4005/10000 [02:09<02:53, 34.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 4000: Success Rate: 24.00%, Avg Reward: -35.7, Epsilon: 0.245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 4505/10000 [02:25<02:48, 32.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 4500: Success Rate: 26.40%, Avg Reward: -32.2, Epsilon: 0.239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5007/10000 [02:40<02:09, 38.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 5000: Success Rate: 24.00%, Avg Reward: -35.8, Epsilon: 0.233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5503/10000 [02:56<03:48, 19.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 5500: Success Rate: 21.00%, Avg Reward: -39.2, Epsilon: 0.228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6004/10000 [03:12<01:55, 34.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 6000: Success Rate: 25.40%, Avg Reward: -32.6, Epsilon: 0.222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 6506/10000 [03:28<01:40, 34.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 6500: Success Rate: 30.00%, Avg Reward: -26.9, Epsilon: 0.217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7006/10000 [03:44<01:24, 35.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 7000: Success Rate: 23.80%, Avg Reward: -36.5, Epsilon: 0.211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 7506/10000 [03:59<01:12, 34.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 7500: Success Rate: 29.60%, Avg Reward: -30.2, Epsilon: 0.206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8006/10000 [04:15<00:58, 34.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 8000: Success Rate: 29.00%, Avg Reward: -29.4, Epsilon: 0.201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 8504/10000 [04:32<00:48, 30.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 8500: Success Rate: 29.20%, Avg Reward: -29.1, Epsilon: 0.196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9007/10000 [04:47<00:27, 36.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 9000: Success Rate: 27.40%, Avg Reward: -31.1, Epsilon: 0.191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 9503/10000 [05:03<00:12, 39.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 9500: Success Rate: 29.20%, Avg Reward: -28.8, Epsilon: 0.186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [05:19<00:00, 31.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 10000: Success Rate: 24.60%, Avg Reward: -34.4, Epsilon: 0.182\n",
            "\n",
            "Evaluating on 2000 words...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:52<00:00, 37.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "EVALUATION RESULTS\n",
            "============================================================\n",
            "Total Games: 2000\n",
            "Wins: 645\n",
            "Success Rate: 0.3225 (32.25%)\n",
            "Total Wrong Guesses: 10420\n",
            "Average Wrong per Game: 5.21\n",
            "Total Repeated Guesses: 0\n",
            "Average Repeated per Game: 0.0000\n",
            "------------------------------------------------------------\n",
            "FINAL SCORE = (0.3225 * 2000) - (10420 * 5) - (0 * 2)\n",
            "FINAL SCORE = 645.00 - 52100.00 - 0.00\n",
            "FINAL SCORE = -51455.00\n",
            "============================================================\n",
            "\n",
            "Training complete!\n",
            "Final Success Rate: 32.25%\n",
            "Final Score: -51455.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# DEMO: Watch the trained agent play Hangman interactively\n",
        "# ============================================================================\n",
        "\n",
        "def demo_game(agent, hmm, word=None, max_lives=6):\n",
        "    \"\"\"Show one game being played step-by-step\"\"\"\n",
        "    env = HangmanEnv([word] if word else corpus, max_lives)\n",
        "    state = env.reset(word)\n",
        "    print(\"\\nðŸŽ® Starting a new Hangman game!\")\n",
        "    print(f\"Word length: {len(env.word)} letters\\n\")\n",
        "\n",
        "    step = 0\n",
        "    while not env.done:\n",
        "        step += 1\n",
        "        mask_display = \" \".join(env.mask)\n",
        "        print(f\"Step {step:02d} | Mask: {mask_display} | Lives: {env.lives} | Guessed: {' '.join(sorted(env.guessed))}\")\n",
        "\n",
        "        # Agent chooses next action\n",
        "        action = agent.choose_action(state, training=False)\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "        print(f\"â†’ Agent guesses: '{action.upper()}' | Reward: {reward:+}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        state = next_state\n",
        "\n",
        "    if env.won:\n",
        "        print(f\"âœ… The agent WON! The word was: {env.word.upper()} ðŸŽ‰\")\n",
        "    else:\n",
        "        print(f\"âŒ The agent LOST! The word was: {env.word.upper()}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Run a few demo games\n",
        "# ---------------------------------------------------------------------------\n",
        "print(\"\\n\\n========== DEMO GAMES ==========\")\n",
        "for i in range(3):\n",
        "    demo_word = random.choice(test_words)\n",
        "    demo_game(agent, hmm, word=demo_word)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjthOkRV_KSM",
        "outputId": "6b9eddd9-2834-4045-845a-a229c67afb70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "========== DEMO GAMES ==========\n",
            "\n",
            "ðŸŽ® Starting a new Hangman game!\n",
            "Word length: 7 letters\n",
            "\n",
            "Step 01 | Mask: _ _ _ _ _ _ _ | Lives: 6 | Guessed: \n",
            "â†’ Agent guesses: 'E' | Reward: -10\n",
            "--------------------------------------------------\n",
            "Step 02 | Mask: _ _ _ _ _ _ _ | Lives: 5 | Guessed: e\n",
            "â†’ Agent guesses: 'A' | Reward: +5\n",
            "--------------------------------------------------\n",
            "Step 03 | Mask: _ _ _ a _ _ _ | Lives: 5 | Guessed: a e\n",
            "â†’ Agent guesses: 'T' | Reward: -10\n",
            "--------------------------------------------------\n",
            "Step 04 | Mask: _ _ _ a _ _ _ | Lives: 4 | Guessed: a e t\n",
            "â†’ Agent guesses: 'R' | Reward: -10\n",
            "--------------------------------------------------\n",
            "Step 05 | Mask: _ _ _ a _ _ _ | Lives: 3 | Guessed: a e r t\n",
            "â†’ Agent guesses: 'L' | Reward: -10\n",
            "--------------------------------------------------\n",
            "Step 06 | Mask: _ _ _ a _ _ _ | Lives: 2 | Guessed: a e l r t\n",
            "â†’ Agent guesses: 'N' | Reward: +5\n",
            "--------------------------------------------------\n",
            "Step 07 | Mask: _ _ _ a n _ _ | Lives: 2 | Guessed: a e l n r t\n",
            "â†’ Agent guesses: 'I' | Reward: +10\n",
            "--------------------------------------------------\n",
            "Step 08 | Mask: _ _ i a n i _ | Lives: 2 | Guessed: a e i l n r t\n",
            "â†’ Agent guesses: 'S' | Reward: -10\n",
            "--------------------------------------------------\n",
            "Step 09 | Mask: _ _ i a n i _ | Lives: 1 | Guessed: a e i l n r s t\n",
            "â†’ Agent guesses: 'C' | Reward: +5\n",
            "--------------------------------------------------\n",
            "Step 10 | Mask: _ _ i a n i c | Lives: 1 | Guessed: a c e i l n r s t\n",
            "â†’ Agent guesses: 'P' | Reward: +5\n",
            "--------------------------------------------------\n",
            "Step 11 | Mask: _ p i a n i c | Lives: 1 | Guessed: a c e i l n p r s t\n",
            "â†’ Agent guesses: 'O' | Reward: +55\n",
            "--------------------------------------------------\n",
            "âœ… The agent WON! The word was: OPIANIC ðŸŽ‰\n",
            "============================================================\n",
            "\n",
            "ðŸŽ® Starting a new Hangman game!\n",
            "Word length: 6 letters\n",
            "\n",
            "Step 01 | Mask: _ _ _ _ _ _ | Lives: 6 | Guessed: \n",
            "â†’ Agent guesses: 'E' | Reward: -10\n",
            "--------------------------------------------------\n",
            "Step 02 | Mask: _ _ _ _ _ _ | Lives: 5 | Guessed: e\n",
            "â†’ Agent guesses: 'A' | Reward: +5\n",
            "--------------------------------------------------\n",
            "Step 03 | Mask: _ _ a _ _ _ | Lives: 5 | Guessed: a e\n",
            "â†’ Agent guesses: 'T' | Reward: -10\n",
            "--------------------------------------------------\n",
            "Step 04 | Mask: _ _ a _ _ _ | Lives: 4 | Guessed: a e t\n",
            "â†’ Agent guesses: 'R' | Reward: -10\n",
            "--------------------------------------------------\n",
            "Step 05 | Mask: _ _ a _ _ _ | Lives: 3 | Guessed: a e r t\n",
            "â†’ Agent guesses: 'N' | Reward: -10\n",
            "--------------------------------------------------\n",
            "Step 06 | Mask: _ _ a _ _ _ | Lives: 2 | Guessed: a e n r t\n",
            "â†’ Agent guesses: 'L' | Reward: +5\n",
            "--------------------------------------------------\n",
            "Step 07 | Mask: _ _ a _ _ l | Lives: 2 | Guessed: a e l n r t\n",
            "â†’ Agent guesses: 'C' | Reward: -10\n",
            "--------------------------------------------------\n",
            "Step 08 | Mask: _ _ a _ _ l | Lives: 1 | Guessed: a c e l n r t\n",
            "â†’ Agent guesses: 'I' | Reward: +5\n",
            "--------------------------------------------------\n",
            "Step 09 | Mask: _ _ a i _ l | Lives: 1 | Guessed: a c e i l n r t\n",
            "â†’ Agent guesses: 'S' | Reward: -50\n",
            "--------------------------------------------------\n",
            "âŒ The agent LOST! The word was: GUAIOL\n",
            "============================================================\n",
            "\n",
            "ðŸŽ® Starting a new Hangman game!\n",
            "Word length: 11 letters\n",
            "\n",
            "Step 01 | Mask: _ _ _ _ _ _ _ _ _ _ _ | Lives: 6 | Guessed: \n",
            "â†’ Agent guesses: 'E' | Reward: +5\n",
            "--------------------------------------------------\n",
            "Step 02 | Mask: _ _ _ _ _ _ _ e _ _ _ | Lives: 6 | Guessed: e\n",
            "â†’ Agent guesses: 'S' | Reward: -10\n",
            "--------------------------------------------------\n",
            "Step 03 | Mask: _ _ _ _ _ _ _ e _ _ _ | Lives: 5 | Guessed: e s\n",
            "â†’ Agent guesses: 'R' | Reward: -10\n",
            "--------------------------------------------------\n",
            "Step 04 | Mask: _ _ _ _ _ _ _ e _ _ _ | Lives: 4 | Guessed: e r s\n",
            "â†’ Agent guesses: 'N' | Reward: +5\n",
            "--------------------------------------------------\n",
            "Step 05 | Mask: _ _ _ _ _ _ _ e n _ _ | Lives: 4 | Guessed: e n r s\n",
            "â†’ Agent guesses: 'T' | Reward: +5\n",
            "--------------------------------------------------\n",
            "Step 06 | Mask: t _ _ _ _ _ _ e n _ _ | Lives: 4 | Guessed: e n r s t\n",
            "â†’ Agent guesses: 'I' | Reward: +5\n",
            "--------------------------------------------------\n",
            "Step 07 | Mask: t _ _ _ _ _ _ e n i _ | Lives: 4 | Guessed: e i n r s t\n",
            "â†’ Agent guesses: 'A' | Reward: +5\n",
            "--------------------------------------------------\n",
            "Step 08 | Mask: t _ a _ _ _ _ e n i _ | Lives: 4 | Guessed: a e i n r s t\n",
            "â†’ Agent guesses: 'L' | Reward: +10\n",
            "--------------------------------------------------\n",
            "Step 09 | Mask: t _ a l l _ _ e n i _ | Lives: 4 | Guessed: a e i l n r s t\n",
            "â†’ Agent guesses: 'C' | Reward: +5\n",
            "--------------------------------------------------\n",
            "Step 10 | Mask: t _ a l l _ _ e n i c | Lives: 4 | Guessed: a c e i l n r s t\n",
            "â†’ Agent guesses: 'O' | Reward: +5\n",
            "--------------------------------------------------\n",
            "Step 11 | Mask: t _ a l l o _ e n i c | Lives: 4 | Guessed: a c e i l n o r s t\n",
            "â†’ Agent guesses: 'M' | Reward: -10\n",
            "--------------------------------------------------\n",
            "Step 12 | Mask: t _ a l l o _ e n i c | Lives: 3 | Guessed: a c e i l m n o r s t\n",
            "â†’ Agent guesses: 'H' | Reward: +5\n",
            "--------------------------------------------------\n",
            "Step 13 | Mask: t h a l l o _ e n i c | Lives: 3 | Guessed: a c e h i l m n o r s t\n",
            "â†’ Agent guesses: 'P' | Reward: -10\n",
            "--------------------------------------------------\n",
            "Step 14 | Mask: t h a l l o _ e n i c | Lives: 2 | Guessed: a c e h i l m n o p r s t\n",
            "â†’ Agent guesses: 'G' | Reward: +55\n",
            "--------------------------------------------------\n",
            "âœ… The agent WON! The word was: THALLOGENIC ðŸŽ‰\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kCa2YplwBY3O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}